{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "579ea03b-78f0-41f6-bf6f-f497ff9da0a4",
   "metadata": {},
   "source": [
    "# Lab Assignment Six: Convolutional Network Architectures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb66b2-183a-4663-baa7-e1548e9ca839",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset Selection\n",
    "\n",
    "Ships in Satellite Imagery\n",
    "https://www.kaggle.com/datasets/rhammell/ships-in-satellite-imagery\n",
    "\n",
    "Group: Nick Benso & Benjamin Kuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89d09b3-2305-40f5-888a-372b9494d3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#image name format: {label} _ {scene id} _ {longitude} _ {latitude}.png\n",
    "#label: 0-no ship(includes incomplete ships), 1-ship\n",
    "\n",
    "root = r\"data\\\\shipsnet\\\\shipsnet\\\\\"\n",
    "testfile = r\"0__20150718_184300_090b__-122.35324421973536_37.772113980272394.png\"\n",
    "\n",
    "def loadImg(dir, imgFile):\n",
    "    img = io.imread(dir + imgFile)\n",
    "    return color.rgb2gray(img)\n",
    "\n",
    "def filenameParse(filename):\n",
    "    repl_delim = '__'\n",
    "    str = filename.replace(\".png\", repl_delim)\n",
    "    return str.split('__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20674c4-1395-4f5b-905e-64b3b708649c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#read in all images into np arrays\n",
    "img = []\n",
    "label = []\n",
    "sceneID = []\n",
    "long = []\n",
    "lat = []\n",
    "\n",
    "directory = os.fsencode(root)\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    count = 0\n",
    "    if(filename.endswith(\".png\")):\n",
    "        img.append(loadImg(root, filename).flatten())\n",
    "        parsed = filenameParse(filename)\n",
    "        label.append(parsed[0])\n",
    "        sceneID.append(parsed[1])\n",
    "        long.append(parsed[2].split('_')[0])\n",
    "        lat.append(parsed[2].split('_')[1])\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print(type(img[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b557bb8a-e2f5-436a-9343-07e79144ea12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   data       4000 non-null   object \n",
      " 1   label      4000 non-null   bool   \n",
      " 2   sceneID    4000 non-null   object \n",
      " 3   longitude  4000 non-null   float64\n",
      " 4   latitude   4000 non-null   float64\n",
      "dtypes: bool(1), float64(2), object(2)\n",
      "memory usage: 129.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "      <th>sceneID</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.44731176470588235, 0.4428396078431372, 0.42...</td>\n",
       "      <td>False</td>\n",
       "      <td>20150718_184300_090b</td>\n",
       "      <td>-122.353244</td>\n",
       "      <td>37.772114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.25246235294117647, 0.2510635294117647, 0.25...</td>\n",
       "      <td>False</td>\n",
       "      <td>20150718_184300_090b</td>\n",
       "      <td>-122.384586</td>\n",
       "      <td>37.763521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.3374623529411765, 0.42707019607843133, 0.51...</td>\n",
       "      <td>False</td>\n",
       "      <td>20150718_184300_090b</td>\n",
       "      <td>-122.404775</td>\n",
       "      <td>37.807104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.41511372549019604, 0.4299666666666666, 0.41...</td>\n",
       "      <td>False</td>\n",
       "      <td>20150718_184300_090b</td>\n",
       "      <td>-122.426639</td>\n",
       "      <td>37.809132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.6346462745098039, 0.6262525490196079, 0.590...</td>\n",
       "      <td>False</td>\n",
       "      <td>20150720_184302_0906</td>\n",
       "      <td>-122.218938</td>\n",
       "      <td>37.871723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  label  \\\n",
       "0  [0.44731176470588235, 0.4428396078431372, 0.42...  False   \n",
       "1  [0.25246235294117647, 0.2510635294117647, 0.25...  False   \n",
       "2  [0.3374623529411765, 0.42707019607843133, 0.51...  False   \n",
       "3  [0.41511372549019604, 0.4299666666666666, 0.41...  False   \n",
       "4  [0.6346462745098039, 0.6262525490196079, 0.590...  False   \n",
       "\n",
       "                sceneID   longitude   latitude  \n",
       "0  20150718_184300_090b -122.353244  37.772114  \n",
       "1  20150718_184300_090b -122.384586  37.763521  \n",
       "2  20150718_184300_090b -122.404775  37.807104  \n",
       "3  20150718_184300_090b -122.426639  37.809132  \n",
       "4  20150720_184302_0906 -122.218938  37.871723  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load np arrays into a dataframe\n",
    "d = {'data': img, 'label': label, 'sceneID': sceneID, 'longitude': long, 'latitude': lat}\n",
    "df = pd.DataFrame(data=d)\n",
    "\n",
    "df.label = df.label.astype(int).astype(bool)\n",
    "df.longitude = df.longitude.astype(np.float64)\n",
    "df.latitude = df.latitude.astype(np.float64)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a4f8c-c339-4ad8-bb0e-a80f85852ccb",
   "metadata": {},
   "source": [
    "## Preparation (3 points total)  \n",
    "[1.5 points] Choose and explain what metric(s) you will use to evaluate your algorithmâ€™s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "\n",
    "[1.5 points] Choose the method you will use for dividi\n",
    "ng your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5039f018-386c-49e7-861c-5ef130ddfff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cbb63e9-5313-47cf-9ea7-1982657b971a",
   "metadata": {},
   "source": [
    "## Modeling (6 points total)\n",
    "[1.5 points]  Setup the training to use data expansion in Keras (also called data augmentation). Explain why the chosen data expansion techniques are appropriate for your dataset. You can use the keras ImageGenerator as a pre-processing step OR in the optimization loop. You can also use the Keras-cv augmenter (a separate package: https://keras.io/keras_cv/Links to an external site.)\n",
    "\n",
    "[2 points] Create a convolutional neural network to use on your data using Keras. Investigate at least two different convolutional network architectures (and investigate changing some parameters of each architecture such as the number of filters--at minimum have two variations of each network for a total of four models trained). Use the method of train/test splitting and evaluation metric that you argued for at the beginning of the lab. Visualize the performance of the training and validation sets per iteration (use the \"history\" parameter of Keras). Be sure that models converge.\n",
    "\n",
    "[1.5 points] Visualize the final results of the CNNs and interpret/compare the performances. Use proper statistics as appropriate, especially for comparing models. \n",
    "\n",
    "[1 points] Compare the performance of your convolutional network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic and area under the curve. Use proper statistical comparison techniques.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b46fec-7faf-4790-abb3-5fef4af2be2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb9ca6b-7179-42c1-81a7-ae58ae6f4fd2",
   "metadata": {},
   "source": [
    "## Exceptional Work (1 points total)\n",
    "You have free reign to provide additional analyses. \n",
    "\n",
    "One idea (required for 7000 level students): Use transfer learning to pre-train the weights of your initial layers of your CNN. Compare the performance when using transfer learning to training without transfer learning (i.e., compare to your best model from above) in terms of classification performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603de18-2291-4540-b4b2-cbf9e89aa9ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
